{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"compare.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"home_win\"], axis=1)\n",
    "y = df.home_win.ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=49)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model One: GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss':['exponential','deviance'],\n",
    "    'learning_rate':[0.05,0.1,0.2,0.3,0.4],\n",
    "    'n_estimators':[10,250,500],\n",
    "    'criterion':['friedman_mse', 'mse', 'mae'],\n",
    "    'min_samples_split':[1,5,10],\n",
    "    'min_samples_leaf':[1,4,8],\n",
    "    'min_weight_fraction_leaf':[0,0.05,0.1],\n",
    "    'max_depth':[2,3,4,7,8,9,None],\n",
    "    'min_impurity_decrease':[0,0.01,0.05],\n",
    "    'max_features':['sqrt','log2',8],\n",
    "    'warm_start':[True,False],\n",
    "    'n_iter_no_change':[25],\n",
    "    'ccp_alpha':[0,1000,2000]   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-63858458e4ea>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-63858458e4ea>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    'warm_start': False, 'n_iter_no_change': 25, 'n_estimators': 250, 'min_weight_fraction_leaf': 0, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0, 'max_features': 8, 'max_depth': 3, 'loss': 'exponential', 'learning_rate': 0.1, 'criterion': 'friedman_mse'\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# I ran this code block separately on a VM, to get the parameters\n",
    "# featured below\n",
    "'''\n",
    "# run a RandomizedSearch\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "gbc = GradientBoostingClassifier()\n",
    "gb_cv = RandomizedSearchCV(gbc, params, n_jobs=-1, n_iter=500)\n",
    "gb_cv.fit(X_train, y_train)\n",
    "print(gb_cv.best_params_)\n",
    "'''\n",
    "\n",
    "'warm_start': False, 'n_iter_no_change': 25, 'n_estimators': 250, 'min_weight_fraction_leaf': 0, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0, 'max_features': 8, 'max_depth': 3, 'loss': 'exponential', 'learning_rate': 0.1, 'criterion': 'friedman_mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search's Tuned GBC AUROC= 0.637\n"
     ]
    }
   ],
   "source": [
    "# check AUROC of gbc with best parameters found in random search\n",
    "gbc = GradientBoostingClassifier(warm_start= False, random_state= 49,\n",
    "                                 n_iter_no_change= 25, n_estimators= 500, \n",
    "                                 min_weight_fraction_leaf= 0.05, min_samples_split= 5,\n",
    "                                 min_samples_leaf= 1, min_impurity_decrease= 0.05,\n",
    "                                 max_features= 'sqrt', max_depth= 2, loss= 'exponential',\n",
    "                                 learning_rate= 0.4, criterion = 'mae', ccp_alpha= 0)\n",
    "gbc.fit(X_train,y_train)\n",
    "y_pred = gbc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Random Search's Tuned GBC AUROC= \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search's Tuned GBC AUROC= 0.636\n"
     ]
    }
   ],
   "source": [
    "# check AUROC of gbc with best parameters found in PaperSpace's 500 iteration random search\n",
    "gbc = GradientBoostingClassifier(warm_start= False,\n",
    "                                 n_iter_no_change= 25, n_estimators= 250, \n",
    "                                 min_weight_fraction_leaf= 0, min_samples_split= 5,\n",
    "                                 min_samples_leaf= 4, min_impurity_decrease= 0,\n",
    "                                 max_features= 8, max_depth= 3, loss= 'exponential',\n",
    "                                 learning_rate= 0.1, criterion = 'friedman_mse', ccp_alpha= 0)\n",
    "gbc.fit(X_train,y_train)\n",
    "y_pred = gbc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Random Search's Tuned GBC AUROC= \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperopt for tuning (in lieu of random search)\n",
    "from hyperopt import tpe,hp,fmin,STATUS_OK,Trials\n",
    "from hyperopt.pyll.base import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameter space\n",
    "space = {\n",
    "    'loss': 'exponential',\n",
    "    'criterion': 'mae',\n",
    "    'learning_rate': hp.quniform(\"learning_rate\",0.01,0.5,0.01),\n",
    "    'n_estimators': hp.choice('n_estimators',np.arange(10, 1000, 50, dtype=int)),\n",
    "    'min_samples_split':hp.choice(\"min_samples_split\",np.arange(2, 10, 1, dtype=int)),\n",
    "    'min_samples_leaf': hp.choice(\"min_samples_leaf\",np.arange(2, 10, 1, dtype=int)),\n",
    "    'min_weight_fraction_leaf':hp.choice(\"min_weight_fraction_leaf\",[0,0.05,0.1]),\n",
    "    'max_depth': hp.uniform(\"max_depth\",1,12),\n",
    "    'min_impurity_decrease':hp.choice(\"min_impurity_decrease\",[0,0.01,0.05]),\n",
    "    'max_features':hp.choice(\"max_features\",['sqrt','log2',8]),\n",
    "    'warm_start':hp.choice(\"warm_start\", [True,False]),\n",
    "    'ccp_alpha':hp.uniform(\"ccp_alpha\",0,2500)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(space):\n",
    "    clf = GradientBoostingClassifier(loss= space['loss'],\n",
    "                                     learning_rate=space['learning_rate'],\n",
    "                                     n_estimators=space['n_estimators'],\n",
    "                                     criterion = space['criterion'],\n",
    "                                     min_samples_split=space['min_samples_split'],\n",
    "                                     min_samples_leaf=space['min_samples_leaf'],\n",
    "                                     min_weight_fraction_leaf=space['min_weight_fraction_leaf'],\n",
    "                                     max_depth=space['max_depth'],\n",
    "                                     min_impurity_decrease=space['min_impurity_decrease'],\n",
    "                                     max_features=space['max_features'],\n",
    "                                     warm_start=space['warm_start'],\n",
    "                                     ccp_alpha=space['ccp_alpha'],\n",
    "                                    )\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    acc = cross_val_score(clf, X_train, y_train, cv=5).mean()\n",
    "    return{'loss':-acc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 25/25 [66:14:20<00:00, 9538.44s/trial, best loss: -0.5979743622430622]\n",
      "Best: {'ccp_alpha': 1120.172193833575, 'learning_rate': 0.43, 'max_depth': 8.121216684877313, 'max_features': 0, 'min_impurity_decrease': 0, 'min_samples_leaf': 6, 'min_samples_split': 6, 'min_weight_fraction_leaf': 2, 'n_estimators': 10, 'warm_start': 0}\n"
     ]
    }
   ],
   "source": [
    "# initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=25,\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperOpt's Tuned GBC AUROC= 0.626\n",
      "Tuned GBC Accuracy = 0.654\n"
     ]
    }
   ],
   "source": [
    "# test hyperopt's recommended gbc here for AUROC\n",
    "gbc = GradientBoostingClassifier(learning_rate=0.43,\n",
    "                                     n_estimators=10,\n",
    "                                     criterion='mse',\n",
    "                                     min_samples_split=6,\n",
    "                                     min_samples_leaf=6,\n",
    "                                     min_weight_fraction_leaf=0.1,\n",
    "                                     max_depth=8,\n",
    "                                     max_features=None,\n",
    "                                     warm_start=False,\n",
    "                                     ccp_alpha=0\n",
    "                                    )\n",
    "gbc.fit(X_train,y_train)\n",
    "y_pred = gbc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"HyperOpt's Tuned GBC AUROC= \" + str(round(roc_auc,3)))\n",
    "# check accuracy\n",
    "predictions = pd.DataFrame(y_pred, columns=['home_win_prob'])\n",
    "predictions['binary'] = predictions['home_win_prob'] > 0.5\n",
    "y_pred = np.array(predictions['binary'])\n",
    "print(\"Tuned GBC Accuracy = \" + str(round(accuracy_score(y_test,y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperOpt's Tuned GBC AUROC= 0.599\n",
      "Tuned GBC Accuracy = 0.622\n"
     ]
    }
   ],
   "source": [
    "# test hyperopt's recommended gbc here for AUROC\n",
    "gbc = GradientBoostingClassifier(learning_rate=0.42,\n",
    "                                     n_estimators=16,\n",
    "                                     criterion='mse',\n",
    "                                     min_samples_split=5,\n",
    "                                     min_samples_leaf=6,\n",
    "                                     min_weight_fraction_leaf=0,\n",
    "                                     max_depth=10,\n",
    "                                     min_impurity_decrease=0,\n",
    "                                     max_features=8,\n",
    "                                     warm_start=True,\n",
    "                                     ccp_alpha=0\n",
    "                                    )\n",
    "gbc.fit(X_train,y_train)\n",
    "y_pred = gbc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"HyperOpt's Tuned GBC AUROC= \" + str(round(roc_auc,3)))\n",
    "# check accuracy\n",
    "predictions = pd.DataFrame(y_pred, columns=['home_win_prob'])\n",
    "predictions['binary'] = predictions['home_win_prob'] > 0.5\n",
    "y_pred = np.array(predictions['binary'])\n",
    "print(\"Tuned GBC Accuracy = \" + str(round(accuracy_score(y_test,y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried RandomSearch and HyperOpt to see which could find the better set of hyperparameters for our GradientBoostingClassifier.\n",
    "\n",
    "Our RandomSearch found a model with an accuracy of __________\n",
    "Our HyperOpt found a model with an accuracy of _______.\n",
    "\n",
    "The best performing GradientBoostingClassifier we have has these hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc final model\n",
    "gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv(\"/storage/compare.csv\")\n",
    "\n",
    "X = df.drop([\"home_win\"], axis=1)\n",
    "y = df.home_win.ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=49)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "params = {\n",
    "    'loss':['exponential','deviance'],\n",
    "    'learning_rate':[0.05,0.1,0.2,0.3,0.4],\n",
    "    'n_estimators':[10,250,500],\n",
    "    'criterion':['friedman_mse', 'mse', 'mae'],\n",
    "    'min_samples_split':[2,5,10],\n",
    "    'min_samples_leaf':[2,4,8],\n",
    "    'min_weight_fraction_leaf':[0,0.05,0.1],\n",
    "    'max_depth':[2,3,4,7,8,9,None],\n",
    "    'min_impurity_decrease':[0,0.01,0.05],\n",
    "    'max_features':['sqrt','log2',8],\n",
    "    'warm_start':[True,False],\n",
    "    'n_iter_no_change':[25]\n",
    "}\n",
    "\n",
    "# run a RandomizedSearch here\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "gbc = GradientBoostingClassifier()\n",
    "gb_cv = RandomizedSearchCV(gbc, params, n_jobs=-1, n_iter=500)\n",
    "gb_cv.fit(X_train, y_train)\n",
    "print(gb_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Two: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'penalty':['l1','l2','elasticnet','none'],\n",
    "    'fit_intercept':[True,False],\n",
    "    'random_state':[49],\n",
    "    'solver':['newton-cg','lbfgs','liblinear','sag','saga'],\n",
    "    'max_iter':[10,25,100,500],\n",
    "    'warm_start':[True,False],\n",
    "    'n_jobs':[6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': True, 'max_iter': 10, 'n_jobs': 6, 'penalty': 'none', 'random_state': 49, 'solver': 'sag', 'warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "# run a GridSearch here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit_cv = GridSearchCV(logit, param_grid=params, scoring=\"roc_auc\", n_jobs=6)\n",
    "logit_cv.fit(X_train, y_train)\n",
    "print(logit_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Tuned Logit AUROC= 0.625\n"
     ]
    }
   ],
   "source": [
    "# check AUROC for model using best params from the GridSearch\n",
    "logit = LogisticRegression(max_iter=10,penalty='none',solver='sag',warm_start=True)\n",
    "logit.fit(X_train,y_train)\n",
    "y_pred = logit.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"GridSearch Tuned Logit AUROC= \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is less computationally intensive, I ran a GridSearch to tune the Logistic Regression model. It returned a final model result with an AUROC of 0.625.\n",
    "The final model's hyperparameters are included below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final Logit Model\n",
    "logit = LogisticRegression(max_iter=10,penalty='none',solver='sag',warm_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Three: Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Four: Soft Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft voting classifier\n",
    "clf1 = gbc\n",
    "clf2 = logit\n",
    "clf3 = NN\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('gbc', clf1), ('logit', clf2), ('NN', clf3)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Gradient Boost', 'Logit', 'Neural Network', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf.fit(X_train,y_train)\n",
    "y_pred = eclf.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Soft voting AUROC: \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the best performing of the three individual models is __________.\n",
    "The soft voting classifier, by comparison, performs _________________.\n",
    "\n",
    "For the purpose of most accurately predicting game outcomes, I would opt to use the ___________."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
