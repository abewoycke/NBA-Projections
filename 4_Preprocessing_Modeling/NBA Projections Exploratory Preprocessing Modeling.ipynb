{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import tpe, hp, fmin, STATUS_OK,Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "import warnings\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"compare.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"home_win\"], axis=1)\n",
    "y = df.home_win.ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=49)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust format of inputs for neural network classifier\n",
    "predictors = np.matrix(X_train)\n",
    "target = to_categorical(y_train)\n",
    "predictors_test = np.matrix(X_test)\n",
    "target_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter space for optimization\n",
    "space = {\n",
    "    \"n_layers\" : hp.randint(\"n_layers\",62)\n",
    "    \"layer_types\" : hp.choice(\"activation_function\",[\"relu\",\"sigmoid\",\"softmax\",\"softplus\",\"softsign\",\"tanh\",\"selu\",\"elu\",\"exponential\"])\n",
    "    \"nodes_per_layer\" : hp.randint(\"nodes_per_layer\",1000)\n",
    "    \"regularization\" : hp.()\n",
    "    \"learning_rate\" : hp.uniform(\"learning_rate\",0.001,0.999)\n",
    "    \"\" : hp.()\n",
    "    \"\" : hp.()\n",
    "    \"\" : hp.()\n",
    "    \"\" : hp.()\n",
    "    \"\" : hp.()\n",
    "    \"\" : hp.()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function to minimize\n",
    "def neural_network_tuning(params):\n",
    "    clf = create_model(params)\n",
    "    acc = cross_val_score(clf, X, y, scoring=\"accuracy\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create model, required for KerasClassifier\n",
    "def create_model(params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10,activation='relu',input_shape=(14,)))\n",
    "    #model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10,activation='relu',input_shape=(14,)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 140.5502 - accuracy: 0.5223\n",
      "Epoch 2/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 54.6223 - accuracy: 0.5317\n",
      "Epoch 3/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 37.4461 - accuracy: 0.5277\n",
      "Epoch 4/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 20.3501 - accuracy: 0.5324\n",
      "Epoch 5/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 15.7459 - accuracy: 0.5371\n",
      "Epoch 6/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 9.8693 - accuracy: 0.5535\n",
      "Epoch 7/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 6.6958 - accuracy: 0.5491\n",
      "Epoch 8/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 5.7130 - accuracy: 0.5485\n",
      "Epoch 9/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 4.1487 - accuracy: 0.5524\n",
      "Epoch 10/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 5.1739 - accuracy: 0.5465\n",
      "Epoch 11/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 2.5998 - accuracy: 0.5650\n",
      "Epoch 12/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 2.9023 - accuracy: 0.5581\n",
      "Epoch 13/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 2.1859 - accuracy: 0.5634\n",
      "Epoch 14/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 2.6638 - accuracy: 0.5503\n",
      "Epoch 15/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 1.5845 - accuracy: 0.5649\n",
      "Epoch 16/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 1.3331 - accuracy: 0.5717\n",
      "Epoch 17/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 1.3838 - accuracy: 0.5717\n",
      "Epoch 18/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.9332 - accuracy: 0.5878\n",
      "Epoch 19/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.8623 - accuracy: 0.5929\n",
      "Epoch 20/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 1.0268 - accuracy: 0.5874\n",
      "Epoch 21/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.9335 - accuracy: 0.5804\n",
      "Epoch 22/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.8806 - accuracy: 0.5932\n",
      "Epoch 23/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.8636 - accuracy: 0.5860\n",
      "Epoch 24/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.8478 - accuracy: 0.5891\n",
      "Epoch 25/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6886 - accuracy: 0.6099\n",
      "Epoch 26/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.7611 - accuracy: 0.5904\n",
      "Epoch 27/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.7022 - accuracy: 0.6116\n",
      "Epoch 28/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6916 - accuracy: 0.6103\n",
      "Epoch 29/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.7151 - accuracy: 0.6022\n",
      "Epoch 30/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6822 - accuracy: 0.6103\n",
      "Epoch 31/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6728 - accuracy: 0.6116\n",
      "Epoch 32/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6622 - accuracy: 0.6227\n",
      "Epoch 33/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6461 - accuracy: 0.6318\n",
      "Epoch 34/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6712 - accuracy: 0.6081\n",
      "Epoch 35/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6594 - accuracy: 0.6182\n",
      "Epoch 36/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6564 - accuracy: 0.6232\n",
      "Epoch 37/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6467 - accuracy: 0.6278\n",
      "Epoch 38/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6480 - accuracy: 0.6226\n",
      "Epoch 39/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6414 - accuracy: 0.6301\n",
      "Epoch 40/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6493 - accuracy: 0.6199\n",
      "Epoch 41/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6533 - accuracy: 0.6159\n",
      "Epoch 42/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6467 - accuracy: 0.6213\n",
      "Epoch 43/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6451 - accuracy: 0.6247\n",
      "Epoch 44/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6457 - accuracy: 0.6242: 0s - loss: 0.6\n",
      "Epoch 45/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6487 - accuracy: 0.6190\n",
      "Epoch 46/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6449 - accuracy: 0.6237\n",
      "Epoch 47/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.6413 - accuracy: 0.6315\n",
      "Epoch 48/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.7387 - accuracy: 0.5910\n",
      "Epoch 49/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.7139 - accuracy: 0.5942\n",
      "Epoch 50/50\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.7109 - accuracy: 0.5900\n",
      "Best: 0.604566 using {'batch_size': 100, 'epochs': 50}\n",
      "0.595653 (0.008984) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.595917 (0.008823) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.595829 (0.008873) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.604391 (0.019689) with: {'batch_size': 25, 'epochs': 10}\n",
      "0.595653 (0.008984) with: {'batch_size': 25, 'epochs': 50}\n",
      "0.595697 (0.008955) with: {'batch_size': 25, 'epochs': 100}\n",
      "0.577431 (0.032034) with: {'batch_size': 50, 'epochs': 10}\n",
      "0.596224 (0.008672) with: {'batch_size': 50, 'epochs': 50}\n",
      "0.596312 (0.008636) with: {'batch_size': 50, 'epochs': 100}\n",
      "0.497431 (0.107873) with: {'batch_size': 75, 'epochs': 10}\n",
      "0.596004 (0.008775) with: {'batch_size': 75, 'epochs': 50}\n",
      "0.596400 (0.008604) with: {'batch_size': 75, 'epochs': 100}\n",
      "0.571723 (0.077619) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.604566 (0.013755) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.595653 (0.008984) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "batch_size = [10,25,50,75,100]\n",
    "epochs = [10,50,100]\n",
    "param_grid = dict(batch_size=batch_size,epochs=epochs)\n",
    "grid=GridSearchCV(estimator=model,param_grid=param_grid,n_jobs=-1,cv=5)\n",
    "grid_result=grid.fit(X,y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6193503400597984"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train,y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abewo\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6251285287445812"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(X_train,y_train)\n",
    "y_pred = lsvc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abewo\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6245728871352025"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still higher iterations LinearSVC\n",
    "lsvc = LinearSVC(max_iter=10000)\n",
    "lsvc.fit(X_train,y_train)\n",
    "y_pred = lsvc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6257251874557984"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still higher iterations LinearSVC\n",
    "lsvc = LinearSVC(max_iter=15000)\n",
    "lsvc.fit(X_train,y_train)\n",
    "y_pred = lsvc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6257251874557984"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still higher iterations LinearSVC\n",
    "lsvc = LinearSVC(max_iter=17000)\n",
    "lsvc.fit(X_train,y_train)\n",
    "y_pred = lsvc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6257251874557984"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even higher iterations LinearSVC\n",
    "lsvc = LinearSVC(max_iter=25000)\n",
    "lsvc.fit(X_train,y_train)\n",
    "y_pred = lsvc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5851692095571376"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(X_train,y_train)\n",
    "y_pred = knc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5774415620942874"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# three neighbors\n",
    "knc = KNeighborsClassifier(n_neighbors=3)\n",
    "knc.fit(X_train,y_train)\n",
    "y_pred = knc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6029283408302065"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ten neighbors\n",
    "knc = KNeighborsClassifier(n_neighbors=10)\n",
    "knc.fit(X_train,y_train)\n",
    "y_pred = knc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61403824322479"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# twenty neighbors\n",
    "knc = KNeighborsClassifier(n_neighbors=20)\n",
    "knc.fit(X_train,y_train)\n",
    "y_pred = knc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6221657437394146"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 neighbors\n",
    "knc = KNeighborsClassifier(n_neighbors=100)\n",
    "knc.fit(X_train,y_train)\n",
    "y_pred = knc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6127198363799784"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 200 neighbors\n",
    "knc = KNeighborsClassifier(n_neighbors=200)\n",
    "knc.fit(X_train,y_train)\n",
    "y_pred = knc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6134162354351074"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 300 neighbors\n",
    "knc = KNeighborsClassifier(n_neighbors=300)\n",
    "knc.fit(X_train,y_train)\n",
    "y_pred = knc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC Model Roc 0.615\n"
     ]
    }
   ],
   "source": [
    "# for good measure, running a non-linear SVC\n",
    "# initial SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Best SVC Model Roc \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best bagknc Model Roc 0.591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagknc = BaggingClassifier(KNeighborsClassifier())\n",
    "bagknc.fit(X_train,y_train)\n",
    "y_pred=bagknc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Best bagknc Model Roc \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best bagknc Model Roc 0.614\n"
     ]
    }
   ],
   "source": [
    "# bagknc, with better neighbors estimator from earlier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagknc = BaggingClassifier(KNeighborsClassifier(n_neighbors=200))\n",
    "bagknc.fit(X_train,y_train)\n",
    "y_pred=bagknc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Best bagknc Model Roc \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RFC Model Roc 0.618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred=rfc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Initial RFC Model Roc \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial abc ROC: 0.628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train,y_train)\n",
    "y_pred = abc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Initial abc ROC: \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increased Estimators abc ROC: 0.628\n"
     ]
    }
   ],
   "source": [
    "# more estimators for abc\n",
    "abc = AdaBoostClassifier(n_estimators=500)\n",
    "abc.fit(X_train,y_train)\n",
    "y_pred = abc.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Increased Estimators abc ROC: \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial gb ROC: 0.635\n"
     ]
    }
   ],
   "source": [
    "# initial Gradient Boosting Classifier+\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train,y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Initial gb ROC: \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hbgb ROC: 0.621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hbgb = HistGradientBoostingClassifier()\n",
    "hbgb.fit(X_train,y_train)\n",
    "y_pred = hbgb.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Initial hbgb ROC: \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Hard Voting Classifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65 (+/- 0.01) [Logistic Regression]\n",
      "Accuracy: 0.64 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.65 (+/- 0.00) [naive Bayes]\n",
      "Accuracy: 0.66 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard voting initial ROC: 0.629\n"
     ]
    }
   ],
   "source": [
    "eclf.fit(X_train,y_train)\n",
    "y_pred = eclf.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Hard voting initial ROC: \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft voting classifier\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65 (+/- 0.01) [Logistic Regression]\n",
      "Accuracy: 0.64 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.65 (+/- 0.00) [naive Bayes]\n",
      "Accuracy: 0.65 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft voting initial ROC: 0.632\n"
     ]
    }
   ],
   "source": [
    "eclf.fit(X_train,y_train)\n",
    "y_pred = eclf.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Soft voting initial ROC: \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "estimators = [('abc', AdaBoostClassifier()),\n",
    "             ('lsvc', LinearSVC(max_iter=25000)),\n",
    "              ('rfc', RandomForestClassifier())]\n",
    "sclf = StackingClassifier(estimators=estimators, final_estimator=GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Classifier initial ROC: 0.629\n"
     ]
    }
   ],
   "source": [
    "sclf.fit(X_train,y_train)\n",
    "y_pred = sclf.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"Stacked Classifier initial ROC: \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Initial ROC: 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=49).fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"LogReg Initial ROC: \" + str(round(roc_auc,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on the initial AUROC scores for the various models, I am inclined to make and tune the following models:\n",
    "\n",
    "Neural Network\n",
    "GradientBoostingClassifier\n",
    "Logistic Regression\n",
    "\n",
    "After that, I will build a soft voting classifier of these and see how it does."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
